## k-최근접 이웃의 한계
- k-최근접 이웃 회귀는 가장 가까운 샘플을 찾아 타깃을 평균하므로, **새로운 샘플이 훈련 세트의 범위를 벗어나면 올바르게 예측하지 못함**
- 따라서 가장 큰 샘플이 포함되도록 훈련 세트를 다시 만들어야 함

## 선형 회귀
- 대표적인 회귀 알고리즘
- 비교적 간단하고 성능이 뛰어남
- 특성이 하나인 경우, 특성을 가장 잘 나타내는 직선을 학습하는 알고리즘
#### 회귀선 기울기와 산점도 방향성에 따른 결정계수
- 기울기를 계수(coefficent) 또는 가중치(weight)라고 함
1) 일직선인 경우 : 모든 데이터를 하나로 예측 (R<sup>2</sup> 0에 가까워짐)
2) 데이터와 반대 방향인 경우 : 완전히 반대로 예측 (R<sup>2</sup> 음수가 될 수 있음)
3) 데이터와 같은 방향인 경우 : 적절히 예측 (R<sup>2</sup> 1에 가까워짐)
#### 파라미터
- 모델 파라미터 : 머신러닝 알고리즘이 찾은 값
- 모델 기반 학습 : 최적의 모델 파라미터를 탐색하는 방식
- 사례 기반 학습 : 모델 파라미터 없이 훈련 세트를 저장 (k-최근접 이웃)

## 다항 회귀
- 다항식을 활용한 선형 회귀
- 함수는 비선형일 수 있지만 선형 회귀로 표현 가능
- 선형 회귀보다 조금 더 복잡함
