 마크다운
- ##으로 시작
- 내부적으로 기능 구현이 되어 있어 구동되는 것이 아닌, 직접 작성하는 것
- 마크업 언어의 일부
- 코드가 일반적인 소스 코드라면 텍스트는 마크다운 언어로 표현된 코드 


분류와 회귀
- 대표적인 지도 학습
- 도출 결과: 이산적 vs 연속적


딥러닝을 위한 norm, 벡터의 길이 측정 방법은 2가지가 있다.
- 멘하튼 : 절댓값의 합(도시명에서 유래, 직선 거리 x), one norm(|)
- 유클리드 : 제곱합의 제곱근(일반적인 직선 거리), two norm(||)


변수가 다양하다면 엄밀히 구분하기 어려움

- knn에서 k는 홀수(만약 짝수라면 동률 발생 가능)
- k값이 작을수록 좋을 수 있긴함.


비선형은 말 그대로 선형이 아닌 것, 비선형이 곡면 또는 곡선 형태인 것만은 아님 \
머신러닝은 통계 기반이다. 선형적 패턴 \
비선형적이면 하나로 설명하기 어려워짐 \
(ex.키와 몸무게 1cm 늘면 3kg 는다. 딥러닝은 키 하나만으로 설명하기 어려움) 


2차원 리스트를 의미하는 표현은 리스트의 리스트 외에도 matrix, tensor(딥러닝 프레임워크에서 상용됨) 등 다양함.
 
tip. 간단한 의미 파악에는 블로그 글이 많지만 엄밀히 정의된 세부 내용은 공식 사이트에서 찾도록 하자. (ex. 사이킷런)\
tip. 사이킷런에서 제공하는 모델 학습 메소드인 fit() 외에도 transform(), fit_transform()을 알아두자.\
(다른 장에서도 작성했지만 fit(), fit_transform()을 test 데이터에 쓰지 말자.\
test 데이터는 모델이 처음 보는, 즉 모델 학습 과정을 거치지 않은 데이터이다.)

숫자로 변환 - 스케일러


score() 정확도 
-정확도만 가지고 판단하면 안 된다.
- 모델 평가도는 정확도 외에도 민감도, 특이도, 재현도 등 다양하다.
  지금 당장 급하진 않지만 영어 표현에 익숙해지자.\
  (자료구조 때 트리로 데여본 걸 떠올려보자.ㅎㅎ)
- 알다시피 이 연산들은 베이즈 정리를 기반으로 한다. 당연하지만 AI수학에서 괜히 학습하는 게 아님.

샘플링 편향 or 불균형
- 교안처럼 데이터 접근하면 비효율적. index로 접근하기 어려움
- 마찬가지로 사이킷런에서 제공하는 좋은 게 있음, train_test_split()

test_train_split()
- 전체 데이터셋을 훈련용과 테스트용으로 분할
- 보통 다음과 같은 형식이다.\
 X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

  - 참고로, 정답 레이블을 맞추는 분류가 아닌, 추세를 통해 데이터 값을 예측하는\
    연속형 레이블의 회귀는 특성 데이터(위의 X)만 제공해도 된다. 

stratify()
- 전체 데이터의 비율, 즉 모수의 비율을 똑같이 반영
- ex) 전체 데이터가 7대3 비율 -> 테스트도 7대3

![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/129747097/6edb9872-6a28-4013-a268-018b20fcba58)

- 글보다는 그림이 이해가 쉬울 것 같다.(사진에는 true인데, 보통 열 이름이나 타깃값을 주는 경우가 많다.) 

random_state
- 데이터를 섞기 전 초기화하는 난수 생성기(seed)
- 값 자체가 갖는 의미는 크지 않다. 데이터를 섞기 위함이지, 데이터셋의 크기와는 연관이 없다.
- 값을 고정하면 동일한 순서가 되니 실험의 일관성과 안정성, 재현성에 좋다.
- 물론 다른 데이터에 대한 반복 실험을 진행할 것이라면 다른 값을 줘도 되겠지. 

그 외) \
feature와 parameter는 상이하다.(-> 지금 보니 당연한 소리..ㅎㅎ) \
parameter와 hyperparameter도 상이하다.

hyper parameter : 사용자가 직접 조정함.\
parameter : 데이터 혹은 모델을 통해 결정됨.

numpy를 통해 리스트가 아닌 배열을 사용하는 이유에는 효율성에 있다. 

data leakage in Training, Validation, Test
