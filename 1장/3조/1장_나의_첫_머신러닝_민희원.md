# 1장 나의 첫 머신러닝(1-1 ~ 1-3장)
1장을 학습하며 추가로 찾아본 내용과 함께 정리하였습니다.

## 인공지능(AI, Artificial Intelligence)
> 인공적으로 만들어진 지능을 가지는 실체, 또는 그것을 만들고자 함으로써 지능 자체를 연구하는 분야 (출처: 인공지능 학회지)

사람처럼 학습하고 추론할 수 있는 지능을 가진 컴퓨터 시스템을 만드는 기술.

## 인공지능의 역사
<details>
<summary>
인공지능의 탄생과 첫번째 암흑기
</summary>

1950년 영국수학자 **앨런 튜링**은 ‘계산 기계와 지능(Computing Machinery and Intelligence)’라는 논문에서 기계가 생각할 수 있는지 테스트하는 방법, 지능적 기계의 개발 가능성, 학습하는 기계 등에 대해 기술.

한편 미국의 신경외과의 워렌 맥컬록과 논리학자 월터피츠가 인공신경을 그물망 형태로 연결하면 사람의 뇌에서 동작하는 아주 간단한 기능을 흉내 낼 수 있다는 것을 이론적으로 증명함(1943년). 또한 헵은 생물학적 신경망 내에서 반복적인 시그널이 발생할 때 신경세포들은 그 시그널을 기억하는 일종의 학습효과가 있음을 증명.

이러한 연구들은 1957년 코넬대 심리학자 프랭크 로센블래트의 연구에 결정적 영향을 주게 되었고, 이 연구에서 **퍼셉트론**(Perceptron: 뇌 신경을 모사한 인공 신경 뉴런) 탄생하게 됨. 이로써 신경망 기반 인공지능 연구의 부흥기에 접어 들게 됨.

하지만 1969년 마빈 민스키와 세이무어 페퍼트는 저서를 통해 퍼셉트론은 AND 또는 OR 같은 선형 분리가 가능한 문제는 가능하지만, **XOR문제에는 적용할 수 없다**는 것을 수학적 증명으로 발표함. 이에 따라 미국방부 DARPA는 AI 연구자금을 2천만달러를 전격 중단하기에 이르렀음. **사실상 인공지능에 대한 대규모 연구는 중단되어 암흑기에 접어들게 됨.**

</details>

<details>
<summary>
인공지능의 두번째 암흑기
</summary>

1970년대 이후 대부분 기업은 R&D의 방향을 **실용적인 통계기술에 집중**하게 됨. 
현대통계학은 1900년대 피셔/피어슨을 선두로 시작하여, 영국의 조지 박스, 일본의 다꾸치 같은 학자들의 노력으로 발전하게 됨. 

이들은 실험계획법 및 통계 분석기술로 제조 품질/생산효율 향상에 영향을 줄 수 있음을 보였으며, 이 개념은 **데이터마이닝**이라는 이름으로 산업에 비효율성을 해결하는 도구로 현재까지 사용되어왔고 **빅데이터 기술의 근간**이 되어 자리 잡게 됨.

한동안 잠잠했던 인공지능 연구는 1980년대 산업계에 **전문가 시스템**이 도입되며 본격적으로 확산하게 됨.

*전문가 시스템은 1)지식과 경험의 데이터베이스화 2) 의사결정 추론엔진 3) 사용자 인터페이스로 구성*

당시 미국의 500대 기업 절반이상이 전문가시스템을 사용했고 지속적인 투자를 한동안 받았음. 하지만 **방대한 관리방안과 투자대비 효용성의 한계가 노출되어 인공지능의 연구는 약해지고**, 1993년 미국부터 대부분 연구방향은 슈퍼컴퓨터와 시뮬레이션 분야로 연구방향을 전환하게 됩니다.

하지만 이런 **인공지능의 암흑기**에서도 리처드 밸벨만 등이 주창한 기계제어를 위한 **강화학습**(Reinforcement Learning), 조지 박스와 일본의 품질 연구가들이 주창한 **실험계획법 및 통계적 공정(품질) 기법들이 산업 분야에 활용되어왔음**. 반면 딥러닝의 기초모델인 역전파 등의 획기적인 AI 연구들이 발표는 되었지만, **컴퓨터 성능 및 제한적인 활용, 머신러닝 알고리즘으로 대체되는 등 여러 제한으로 인하여 세상에 주목 받지 못하고 사장되어 갔음.**

[+ 참고한 문서](https://www.samsungsds.com/kr/insights/091517_cx_cvp3.html)
</details>

## 인공지능의 세가지 발전 단계
- 약인공지능(Weak AI): 
약인공지능은 **특정 주제의 분야에서 주어진 일을 인간의 의도에 따라 수행하는 인공지능**으로, 방대한 양의 데이터를 학습시켜 인간의 프로그래밍 없이도 **스스로 인간의 특정 문제를 해결하는 것을 목적**으로 한다.

  약인공지능은 **문제 해결 자체에 포커스**가 맞추어져 있다. 자연어처리(NLP)를 비롯하여 객체인식(Object Detection), 이상치 탐지(Anomaly Detection) 등 거의 모든 인공지능의 세부 분야와 기술들은 모두 인간의 문제 해결을 목적으로 탄생했다. **그 어떠한 약인공지능도 인간의 개입 없이 완전히 스스로 생각하고 행동할 수 없다.**

  약인공지능은 아직까지는 특정 분야에서 사람의 일을 도와주는 보조 역할만 가능하다.
  ex) 음성 비서, 자율 주행 자동차, 음악 추천, 기계 번역, 알파고 등

- 강인공지능(Strong AI 혹은 인공일반지능, Artificial general intelligence): **컴퓨터에 인간의 것과 동일한 수준의 지성을 구현하고자 하는 시도**인데, 인공일반지능(Artificial General Intelligence)이라고 하기도 한다. 아직까지 강인공지능은 공상과학과 상상의 영역에만 존재한다고 봐도 무방하다.


  ex) 그녀(Her), A.I로봇, 엑스마키나(Ex Machina) 등 공상과학영화에 등장하는 인공지능. 

  최근 화제가 되고있는 챗GPT와 같은 LLM의 학습 데이터와 매개변수가 계속해서 증가하며 발전을 거듭하게 되면서 인간의 것과 비슷한 추론능력(Inference)을 획득한 사례를 들며, 결국은 미래에 기계가 지능을 획득할 수 있을 것이라는 주장과, 기계와 인간의 지능은 근본적으로 다르며 인공지능은 결국 인간과 같은 수준의 지성을 획득하지 못할 것이라는 주장이 대립하고 있다.

- 초인공지능(ASI, Artificial super intelligence): 챗GPT의 등장을 계기로 **인류의 지능을 뛰어넘어 스스로 목표를 설정하고 지능을 강화**하는 ‘초인공지능(Artificial Super Intelligence)’의 위협에 대비해야 한다고 목소리를 내는 사람들도 늘어났다.

  [+ 참고한 문서](https://blog-ko.superb-ai.com/ai-singularity-ai-agi-and-asi/)


## 머신러닝(ML, Machine Learning)
- 머신러닝 ≠ 모든규칙의 학습

- 규칙을 일일이 프로그래밍하지 않아도 **자동으로 데이터에서 규칙을 학습하는 알고리즘**을 연구하는 분야

- 인공지능의 하위 분야 중에서 지능을 구현하기 위한 소프트웨어를 담당하는 핵심 분야

- 컴퓨터 과학분야의 대표적인 머신러닝 라이브러리는 [**사이킷런**](https://scikit-learn.org/stable/)이다.


## 딥러닝(Deep learning)
머신러닝 알고리즘 중에 **인공 신경망**(Artificial neural network)을 기반으로 한 방법들을 통칭하여 **딥러닝**이라 부름.

- **인공 신경망(ANN) 알고리즘을 개선**하여 기존의 한계를 극복한 방식
- 뉴럴 네트워크는 **생체 뉴런의 정보전달 방식**을 **수학적 알고리즘**으로 모사
- **텐서플로**와 **파이토치**가 대표적인 라이브러리


## 생선 분류 문제
### **Data Leakage(데이터 누수, 정보 누설) 문제 주의** 
미래에 대한 전혀 알 수 없는 대한 정보가 모델 학습에 사용된 경우. 학습에 사용해야하는 데이터인 train data가 아닌 test data에 대한 정보를 활용하면 이는 Data Leakage로 볼 수 있음.

[+ 참고하면 좋을 것 같은 글](https://comgenie.tistory.com/99)

### 선형(Linear)과 비선형(Nonlinear)
1. 선형(Linear)
   - 직선 형태로 나타낼 수 있는 관계를 의미.
   - 선형 모델은 간단하며 해석이 쉽지만, 데이터의 복잡한 패턴을 설명하기에는 제한이 있을 수 있음.
2. 비선형(Nonlinear)
   - 직선형태로 나타낼 수 없는 관계. 즉, 선형이 아닌 것.

### KNN(K-최근접 이웃, K-Nearest Neighbors)
KNN은 **instance-based 학습**(사례 중심 학습)에 속하며, 주어진 데이터의 근처 이웃들을 활용하여 예측을 수행함.

*Instance-Based Learning: 훈련 데이터를 저장하고, 새로운 입력 데이터와 가장 유사한 훈련 데이터 포인트들을 찾아 예측하는 학습 방법*

- 새로운 데이터 포인트가 주어지면, 가장 가까운 이웃들을 찾아 해당 이웃들의 레이블을 기반으로 예측을 수행함.
- 이때, "가깝다"는 개념은 주로 유클리디안 거리나 맨하탄 거리와 같은 거리 측정 방법을 사용하여 정의됨.

**KNN에서 K를 홀수로 선택하는 이유**는 주로 다수결 투표 방식을 사용하기 때문이다. K가 홀수인 경우 동점이 나올 확률이 낮아지며, 예측의 불확실성을 줄일 수 있다. 그리고 일반적으로 K의 값이 작으면 작을수록 좋다. 이때, **K**는 모델 학습 전에 사람이 수동으로 설정해야하는 **하이퍼파라미터**(Hyperparameter)에 속한다.

*파라미터(Parameter)는 모델이 데이터로부터 학습되면서 자동으로 조절되는 값.*

### score() 메서드
모델의 성능을 평가하는 데 사용되고, 주로 사이킷런 라이브러리에서 사용된다.

- **'score()'** 메서드는 일반적으로 정확도(accuracy)를 반환함.
- 정확도는 정확히 예측된 샘플의 비율로, 전체 예측한 샘플 중에서 실제와 일치하는 샘플의 비율을 나타냄.
- 분류 모델에서는 정확도(accuracy), 회귀 모델에서는 결정 계수(R-squared) 등을 반환함.
- 다른 성능 지표 : 오차행렬(Confusion Matrix), Precision(정밀도), Recall(재현율), Sensitivity(민감도) 등