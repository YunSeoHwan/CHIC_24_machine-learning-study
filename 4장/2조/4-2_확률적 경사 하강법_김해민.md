<경사 하강법 알고리즘을 이해하고 대량의 데이터에서 분류 모델을 훈련하는 방법>
## 점진적 학습
앞서 훈련한 모델을 버리지 않고 새로운 데이터에 대해서만 조금씩 더 훈련하는 방법

-> 대표적인 알고리즘: 확률적 경사 하강법

## 확률적 경사 하강법
훈련세트에서 랜덤하게 하나의 샘플을 선택하여 가파른 경사를 조금 내려간 후 그다음 훈련세트에서 랜덤하게 또 다른 샘플을 하나 선택하여 경사를 조금 내려감

샘플을 다 사용했는데 끝까지 못 내려올 경우 다시 처음 샘플부터 시작
- 에포크
  : 확률적 경사 하강법에서 훈련 세트를 한 번 모두 사용하는 과정

  일반적으로 경사하강법은 수십, 수백 번 이상 에포크 수행
## 미니배치 경사 하강법
여러 개의 샘플을 사용해 경사 하강법을 수행하는 방식
## 배치 경사 하강법
한 번 경사로를 따라 이동하기 위해 전체 샘플 사용

## 손실함수
어떤 문제에서 머신러닝 알고리즘이 얼마나 엉터리인지를 측정하는 기준
- 로지스틱 손실함수(이진 크로스엔트로피 손실함수)
- 크로스엔트로피 손실함수
  : 다중분류에서 사용하는 손실함수

## 에포크와 과대, 과소적합
- 조기종료
  : 과대적합이 시작하기 전에 훈련을 멈추는 것
