## 점진적 학습
이전에 훈련한 모델을 버리고 다시 새로운 모델을 훈련하는 방법
#### 확률 경사 하강법
확률적 : 무작위하게  
경사 : 기울기  
하강법 : 내려가는 방법  
=> 하나의 샘플을 훈련 세트에서 랜덤하게 골라 가장 가파른 길을 찾는 것, 그래도 다 내려오지 못하면 처음부터 다시 시작  
에포크 : 확률적 경사 하강법에서 훈련 세트를 한번 모두 사용하는 과정, 일반적으로 경사 하강법은 수백번 이상의 에포크 수행함

#### 미니배치 경사 하강법
무작위로 몇개의 샘플을 선택해서 경사를 따라 내려가는 방법  
partial_fit사용해서 계속 찾아감
```
import numpy as np
sc = SGDClassifier(loss='log', random_state=42)
train_score = []
test_score = []
classes = np.unique(train_target)

for _ in range(0,300):
  sc.partial_fit(train_scaled, train_target, classes = classes)
  train_score.append(sc.score(train_scaled, train_target))
  test_score.append(sc.score(test_scaled, test_target))

#반복 횟수 100에 맞추고 모델 다시 훈련
sc = SGDClassifier(loss = 'log', max_iter=100, tol=None, random_state=42)
sc.fit(train_scaled, train_target)
print(sc.score(train_scaled, train_target))
print(sc.score(test_scaled, test_target))

#SGDClassifier는 일정 에포크동안 성능 향상되지 않으면 자동으로 더 훈련하지 않고 멈춤 근데 우리는 결과 보기 위해 tol=None으로 설정하고 100만큼 반복하도록 임의 설정 한거임
```
#### 배치 경사 하강법
전체 샘플을 사용

<br />

**손실함수** : 머신러닝 알고리즘이 얼마나 엉터리인지 측정 => 손실함수의 값이 작을수록 좋음 but 어떤 값이 최솟값인지는 알지 못함  
SGDClassifier의 loss매개변수의 기본값은 hinge임
=> 힌지손실(= 서포트 벡터 머신)은 또 다른 머신러닝 알고리즘을 위한 손실 함수임  
서포트 벡터 머신이 널리 사용하는 머신 러닝 알고리즘 중 하나이고, SGDClassifier가 여러 종류의 손실함수를 loss매개변수에 지정하여 다양한 머신 러닝 알고리즘을 지원하는 것만 알면 됨  
```
#힌지 손실을 사용해 같은 반복 횟수동안 모델 훈련
sc = SGDClassifier(loss = 'hinge', max_iter=100, tol=None, random_state=42)
sc.fit(train_scaled, train_target)
print(sc.score(train_scaled, train_target))
print(sc.score(test_scaled, test_target))
```
