# 4-1. 로지스틱 회귀

## 로지스틱 회귀

>로지스틱 회귀(Logistic Regression) : 데이터가 어떤 범주에 속할 확률을 0에서 1 사이의 값으로 예측하고 확률에 따라 가능성이 더 높은 범주로 분류하는 지도 학습 알고리즘

### 시그모이드 함수

>시그모이드 함수(Sigmoid Function) : 선형 방정식의 출력 z의 음수를 사용해 자연 상수 e를 거듭제곱하고 1을 더한 값의 역수로 계산하는 함수. z가 무한하게 큰 음수일 경우 0에 가까워지고 z가 무한하게 큰 양수가 될 시에는 1에 가까워지며 z가 0일 경우 0.5임. 로지스틱 회귀에서 사용되는 활성화 함수. ([활성화_함수의_종류](https://blog.naver.com/PostView.nhn?isHttpsRedirect=true&blogId=handuelly&logNo=221824080339))

```
import numpy as np
import matplotlib.pyplot as plt

z = np.arange(-5, 5, 0.1)
phi = 1 / (1 + np.exp(-z))

plt.plot(z, phi)
plt.xlabel('z')
plt.ylabel('phi')
plt.show()
```

### 소프트맥스 함수

>소프트맥스 함수(Softmax Function) : 다중 분류에서 z값을 0과 1 사이의 값으로 바꾸어 확률로 변환해주는 함수

```
from scipy.special import softmax
```
