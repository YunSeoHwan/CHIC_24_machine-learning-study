# 차원 축소
: 원본 데이터의 특성을 적은 수의 새로운 특성으로 변환하는 비지도 학습의 한 종류
- 차원 : 머신러닝에서 특성을 차원이라고 부름
  - 특성 : 데이터가 가진 속성
  - 차원을 줄이면 저장공간 크게 절약 가능 + 시각화하기도 쉬움 + 다른 알고리즘의 성능 향상에도 도움
  
# 주성분 분석(PCA)
: 데이터에서 가장 분산이 큰 방향을 찾는 방법 --> 이 방법을 주성분이라고 부름
- 대표저긴 차원 축소 알고리즘
- 데이터에 있는 분산이 큰 방향을 찾는 것으로 이해
  - 분산 : 데이터가 널리 퍼져있는 정도
    - 분산이 큰 방향이란 데이터를 잘 표현하는 어떤 벡터, 이 벡터를 주성분이라고 부름
- 원본 데이터를 주성분에 투영해 새로운 특성을 만들 수 있음
- 일반적으로 주성분은 원본 데이터에 있는 특성 개수보다 작음
- 원본 차원과 같고 주성분으로 바꾼 데이터는 차원이 줄어듦
  - 주성분이 가장 분산이 큰 방향이기에 주성분에 투영해 바꾼 데이터는 원본을 가지고 있는 특성을 가장 잘 나타내고 있음
- PCA 클래스 
  - 사이킷런은 sklearn.decomposition 모듈 아래 PCA 클래스로 주성분 분석 알고리즘 제공
  - n_components 매개변수에 주성분의 개수를 지정해야 함
  - k-평균과 마찬가지로 비지도 학습이기 때문에 fit() 메서드에 타깃값 재공 안 함.
  - components_ 속성 : PCA 클래스가 찾은 주성분이 저장되어 있음
  - inverse_transform() 메서드 : 
    - transfrom() 메서드로 차원을 추속시킨 데이터를 다시 원본 차원으로 복원
    - 원본 데이터 상다 부분 재구성하느데 사용하는 함수
  - explained_variance_ 속성 : 설명된 분산 저장
  - explained_variance_ratio_ 속성 : 설명된 분산의 비율 저장
  
# 설명된 분산
: 주성분 분석에서 주성분이 원본 데이터의 분산을 얼마나 잘 나타내는지 기록한 값
- PCA 클래스
  - 주성분 개수나 설명된 부난의 비율을 지정해 주성분 분석을 수행할 수 있음
  - explained_variance_ratio_에 각 주성분의 설명된 분산 비율이 기록되어 있음
    - 첫 번째 주성분의 설명된 분산이 가장 큼
    - 분산 비율을 모두 더하면 주성분으로 표현하고 있는 총 분산 비율을 얻을 수 있음
