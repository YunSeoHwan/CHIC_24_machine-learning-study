### <다섯 번째 스터디 - 2024.2.8.>
### 범위: p.242~337
##### 비지도학습이란
정답을 알려주지 않고 비슷한 데이터를 군집화하는 것 (라벨이 존재하지 않음)
군집분석(Clustering)와 차원 축소(Dimensionality Reduction)가 있음
##### K-Means
- 클러스터링의 대표적인 알고리즘
- 약점: 원형분포 / 달 모양 분포 / 태극문양 등의 데이터들을 클러스터링 하는 데 어려움이 있음
- k 값을 직접 지정해주어야 함(hyperparameter)

##### 비지도학습에서의 과대적합
- 비지도학습에도 과대적합이 존재함. 책에서는 cluster를 기준으로 다뤘는데, clustering은 2차원에서 가능(시각화를 위해서). k-means는 density한 군집을 잡지 못함 (예를들어, 도넛모양,태극모양) 이유: Euclidian distance를 사용하기 때문에.
- 어떠한 데이터에 대해 판단해야 하는데, 실제로는 아니다. 인위로 label을 붙이는 것. 사후검증이 되면 성능을 판단할 수 있음. "dbscan" -> 기계학습/빅처응 확인해보기.
※ 준지도학습은 절반으로 학습하고 나머지는 검증.
##### PCA에서 차원축소를 진행하면 이미지가 깨지는 것 같음
- PCA자체의 주요목적: 분산을 최대한 보존하면서 차원을 줄이는 HYPER PLANE을 찾는 것. 차원을 줄이게 되면 당연히 고유한 특성을 어느정도는 손실이 있을 것. 그러나 최소화 되어도 득보다 실이 많으면 실행하는 것.
원상복구가 되지는 않음.
- 예를들어, 10차원 -> 2차원 -> 10차원 에서 원상복구가 되지 않는 경우도 있음. "reconstruction error"
##### 차원축소의 필요여부에 대한 판단기준
- 알 수 없음. 우선, DATA ROW(data양)가 많아서 시간이 많이 걸리는지, feature 수가 많아서 시간이 많아서 걸리는지 확인해야 함. feature의 갯수가 지나치게 많다고 생각되면 PCA
- feature 10개 성능 0.7 feature 5개 성능 0.69이면 줄이는게 아마 좋을 것. "사후적인 분석". 물론 feature수가 너무 많으면 하는 것이 좋겠지만.. 
- reconstruction error를 확인하면 얼마의 중요도로 pca가 되었는지 확인 할 수 있음
 