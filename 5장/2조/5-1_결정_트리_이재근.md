## pandas

info() 메서드 / 데이터프레임의 각 열의 데이터 타입과 누락 데이터 확인
-> 누락된 값이 있다면 그 데이터를 버리거나 평균값으로 채운 후 사용
/ 항상 훈련 세트의 통계값으로 테스트 세트를 변환한다는 것을 인지

describe() 메서드 / 열에 대한 간략한 통계 출력(최소, 최대, 평균값 등)

##결정트리
true / false에 대한 질문을 이어나가며 정답을 찾아 학습하는 알고리즘 / 예측 과정을 이해하기 쉽고 성능 뛰어남 
random_state를 지정하는 이유 
-> 사이킷런의 결정 트리 알고리즘은 노드에서 최적의 분할을 찾기 전 특성의 순서를 섞음
따라서 약간의 무작위성이 주입되는데 실행할 때마다 점수가 조금씩 달라질 수 있기 때문

##노드
결정 트리를 구성하는 핵심요소 / 훈련 데이터의 특성에 대한 테스트를 표현 
-> 가지는 테스트의 결과(True, False)를 나타내며 일반적으로 하나의 노드는 2개의 가지를 가짐
-> 맨 위(루트 노드) 맨 아래(리프 노드)

만약 결정 트리를 회귀 문제에 적용하면 리프 노드에 도달한 샘플의 타깃을 평균하여 예측값으로 사용 

##불순도
사이킷런은 지니 불순도와 엔트로피 불순도를 제공

지니 불순도
gini -> DecisionTreeClassifier 클래스의 criterion 매개변수의 기본값

정보이득 -> 부모와 자식 노드 사이의 불순도 차이 / 결정 트리 알고리즘은 정보 이득이 최대화되도록 학습

##가지치기
결정 트리의 성장을 제한하는 방법
결정트리는 제한 없이 성장하면 훈련 세트에 과대적합되기 쉬움!!

##특성 중요도 
결정 트리에 사용된 특성이 불순도를 감소하는데 기여한 정도를 나타내는 값 
-> 특성 중요도를 계산할 수 있는 것이 결정 트리의 장점 

##사이킷런

##DecisionTreeClassifier 
결정 트리 분류 클래스
criterion 매개변수는 불순도를 지정 / 기본값은 gini
entropy를 선택하여 엔트로피 불순도를 사용할 수도 있음 

splitter 매개변수 / 노드를 분할하는 전략 선택 / 기본값은 best -> 정보 이득이 최대가 되도록 분할

max_depth / 트리가 성장할 최대 깊이 지정 / 기본값 None 
-> 리프 노드가 순수하거나 min_samples_split보다 샘플 개수가 적을 때 까지 성장
min_samples_split -> 노드를 나누기 위한 최소 샘플 개수 / 기본값 2 
max_features 매개변수 / 최적의 분할을 위해 탐색할 특성 개수 지정 / 기본값은 None으로 모든 특성 사용

##plot_tree()
결정 트리 모델을 시각화 / 첫 번째 매개변수로 결정 트리 모델 객체를 전달
max_depth 매개변수로 트리의 깊이 지정 / 기본값은 None으로 모든 노드 출력
feature_names 매개변수로 특성 이름 지정 가능 
filled 매개변수를 True로 지정하면 타깃값에 따라 노드 안에 색을 채움
