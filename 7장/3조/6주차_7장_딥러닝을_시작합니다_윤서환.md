# 딥러닝을 시작합니다(7-1, 7-2, 7-3) - 6주차
**7-3**까지 내용을 정리함을 서두에 밝힙니다.<br>
책 내용에서 보다 깊이 있게 다루면 좋을 요소 위주의 정리를 진행했습니다. 따라서 책 전체 내용의 기술되어 있지 않을 수 있습니다. 궁금한 사항이나, 잘못된 부분이 있다면, 언제든 issue에 의견을 남겨주시면 감사하겠습니다. 해당 내용은 **밑바닥부터 시작하는 딥러닝 1**을 참고하여 만들었습니다.


## 1. 학습(Training)
책에서는 잘 다루지 않은 어떻게 신경망이 학습이라는 것을 하게 되는지 기초적이면서 깊게 다뤄보겠습니다. 학습이 가능하려면 **손실 함수(loss function)** 가 필요합니다. 이 손실 함수의 결과값을 최소화하는 매개변수를 찾는 것이 학습의 목표입니다. **어떻게 모델이 스스로 학습을 하고, 손실 함수의 값을 최소화** 할 수 있는지 배워보겠습니다.
<br><br><br>

### 1.1 데이터 주도 학습
**기계학습(ML)은 데이터가 생명이자 곧 중심**입니다. 데이터에서 패턴과 답을 찾기 때문입니다.
<br>
그러나, 이러한 특징과 패턴을 기계가 잘 찾아도, 문제에 적합한 특징과 패턴인지의 결정은 사람이 하게 됩니다. 간단한 예시를 통해 설명하겠습니다.<br><br>

MNIST 숫자 5 이미지를 인식하는 프로그램을 구현하려고 합니다. 사람이 직접 분류하기에는 다소 쉽지만, 이를 프로그램으로 설계하는 것은 생각보다 어려운 문제입니다. 단순히, logic을 이용해서 풀기에는 한계가 있습니다. 아래 그림을 보면 사람마다 작성한 '5'의 이미지도 제각각입니다.
![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/48356954/89df2815-7f39-404c-8d2d-ed6e0e24e9a0)
<br>
그렇기 때문에, 이를 밑바닥부터 설계하는 것보다 **주어진 데이터를 활용**해서 문제를 해결하는 것이 효과적입니다. 그러한 방법의 하나로, 이미지에서 특징(feature)을 추출하고 그 패턴을 기계학습으로 학습하는 방법이 있습니다. 여기서의 특징은 입력 데이터(이미지)에서 본질적인 데이터(이미지)를 정확하게 추출하도록 설계된 변환기를 뜻합니다.

컴퓨터 비전 분야에서는 SIFT, SURF, HOG 등의 특징을 많이 사용합니다. 이를 이용하여, 이미지는 벡터화 한 후, 지도 학습 분류 기법(SVM, KNN) 등으로 학습합니다. 그러나, 이러한 **특징(feature)조차 사람이 직접 설계하기 때문**에 적합한 방식이 아니라면, 좋은 결과를 얻을 수 없습니다.



그러나 **신경망은 이미지를 있는 그대로 학습합니다.** 아래 그림을 보겠습니다.<br>
![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/48356954/7bd50122-96db-47f4-8b94-98535fad9db4)
학습방식
기계학습까지는 사람의 개입으로 특징을 찾았으나, 신경망은 이러한 특징마저 기계가 스스로 학습합니다. 즉, 모든 문제를 주어진 데이터 그대로를 입력 데이터로 활용합니다. 그렇기 때문에 신경망을 포함한 딥러닝을 **end-to-end**이라고 합니다.
<br><br>


### 1.2 Train, Test data
기본적으로 데이터를 가지고 문제를 해결할 때, 일반적으로 **훈련데이터(Train data), 시험 데이터(Test data)로 나눠서 학습**합니다. Train data로 학습을 통해 최적의 매개변수를 찾고, Test data로 model의 성능을 평가합니다.

이렇게 하는 이유는 일**반화(Generalization) 성능을 높이기 위함**입니다. 일반화 성능이란, 아직 보지 못한 데이터로도 문제를 올바르게 해결하는 성능을 뜻합니다. 앞서 숫자 5를 예시로 설명하겠습니다. 


우리의 목표는 '임의의 사람'의 '임의의 글자(여기선 5)'를 잘 판단하는 것이 목표입니다. 그러나 Train data에서만 숫자를 잘 판단한다면, Train data에 포함된 사람의 글씨만 학습했을 가능성이 크다고 볼 수 있습니다. 이러한 상태를 **과적합(Overfitting)** 되었다고 합니다. 그렇기 때문에 하나의 데이터 전부를 학습에만 사용하게 되면 새로운 데이터에 대한 성능을 장담할 수 없습니다.<br>
![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/48356954/bc985538-7c42-4f8c-8ede-22465c134bb1)



반면, 데이터에 비해 지나치게 간단하게 학습을 하게 되면 **과소적합(Underfitting)**이 발생합니다. 이러한 문제를 해결하기 위해서는 모델의 복잡도를 올리면 됩니다. 간단하게는 매개변수를 늘리는 방법이 있습니다. 다만, 지나치게 모델의 복잡도를 올리게 된다면, 다시금 overfitting을 마주하게 됩니다. 그렇기 때문에 적절히 조절하는 것이 중요합니다.

<br><Br>

## 2. 손실 함수(Loss function)
앞서 데이터로부터 매개변수의 최적값을 스스로 학습하려면, 손실 함수가 필요하다고 했습니다. 즉, 신경망 학습을 통해 매개변수의 최적값을 탐색할 때, 기준 지표로 활용되는 것이 바로 **손실 함수(Loss function)**입니다. 임의의 함수를 사용할 수 있지만, 일반적으로 SSE(Sum of Squares Error), CEE(Cross Entroy error)를 사용합니다.
<br><br>

### 2.1 SSE(오차제곱합)
![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/48356954/10cd0426-649e-4e23-978f-93ff0c7b705c)
- y_k : 신경망 예측값
- t_k : 실제값

실제값과 예측값의 차이를 제곱해서 더한 값을 loss function으로 사용합니다. 실제 정답을 1, 그 외는 0으로 나타내는 원핫(One-hot) 인코딩 방식을 이용하여, SSE를 구현해 보겠습니다.

import numpy as np

```
# MSE 함수 구현
def sum_squared_error(y, t):
   return 0.5 * np.sum((y - t)**2)
   
# 정답은 '2' -> one-hot
t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]

# ex1) : '2'일 확률이 가장 높다고 추정함(0.6) -> softmax 결과값
y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]
print('SSE of ex1 =', sum_squared_error(np.array(y), np.array(t)))

# ex2) : '7'일 확률이 가장 높다고 추정함(0.6)
y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]
print('SSE of ex2 =', sum_squared_error(np.array(y), np.array(t)))
```

```
SSE of ex1 = 0.09750000000000003
SSE of ex2 = 0.5975
```

결과값을 보면, 실제 정답일 때의 loss값이 훨씬 적게 나옴을 알 수 있습니다. 즉, **SSE 기준으로 ex1의 loss가 더 적기 때문에 정답에 더 가깝다고 해석**할 수 있습니다.


<br>

### 2.2 Cross Entropy(CE)

![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/48356954/8e4a5a9c-7a72-4d2e-b0c2-cbcbe02e4473)

Cross Entropy도 자주 이용되는 loss function입니다. 해당 loss function은 log가 있기 때문에 \(t_k\)가 0, 즉 정답이 아니라면 0, 정답일 경우에는 자연로그 값을 출력하게 됩니다. **CE는 정답일 때의 출력이 전체 값을 결정**하게 됩니다. 코드를 통해 살펴보겠습니다.


```
def cross_entropy_error(y, t):
    delta = 1e-7    # log0 방지
    return -np.sum(t * np.log(y + delta))
    
# answer = 2
t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]

# answer
y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]
cee_answer = cross_entropy_error(np.array(y), np.array(t))
print(f"Answer : {cee_answer}")

# error
y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]
cee_error = cross_entropy_error(np.array(y), np.array(t))
print(f"Error : {cee_error}")
```


```
Answer : 0.510825457099338
Error : 2.302584092994546
```

실제 정답이 2이기 때문에, 2번 값이 0.6에 할당된 첫 번째 경우가 더 낮은 loss를 가지게 됩니다. CE를 구현할 때, 한 가지 특이점은, delta라는 굉장히 작은 값을 더해줍니다. **log는 0에서 정의가 되지 않기 때문**에 y에 0이 들어왔을 때, 에러가 발생합니다. 그렇기 때문에 약간의 trick을 사용했습니다.

<br><br>

### 2.3 Mini batch
앞서 소개한 loss function은 데이터 하나에 대한 값이었습니다. Train data 모두에 loss function을 적용하려면 다음과 같이 수식을 변경해야 합니다. CE를 예시로 보겠습니다.

![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/48356954/4aa9d04e-bfbd-421c-aa3e-b169fff1b909)
<br>
해당 수식에서 n은 n번째 데이터, t_nk는 n번째 데이터의 k번째 값을 의미합니다. 마지막 N을 나누어주는 이유는 정규화 효과를 가져옵니다. 해당 수식에서는 평균 loss function을 구할 수 있습니다. 해당 수식은 데이터의 개수에 관계없이 평균 loss function을 구할 수 있습니다.

<br>

다만, 데이터의 개수가 많고 특히, 빅데이터라면 시간이 오래 걸리게 됩니다. 그렇기 때문에 Train data 중, 일부만 sampling 하여 학습하게 됩니다. 여기서 일부를 **mini-batch**라 부르고, 이러한 학습 방법을 **mini-batch 학습**이라 합니다. MNIST 데이터를 읽어와 10장의 데이터만 추출하는 코드를 보겠습니다.


```
import sys, os
sys.path.append('your path')
from mnist import load_mnist

(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=False)

print('x_train.shape :', x_train.shape) # image
print('t_train.shape :', t_train.shape) # label

# 무작위 10개 추출
train_size = x_train.shape[0]
batch_size = 10

batch_mask = np.random.choice(train_size, batch_size)   # 60000개 중 10개만 추출

x_batch = x_train[batch_mask]
t_batch = t_train[batch_mask]

print('batch_mask :', batch_mask)
print('x_batch.shape :', x_batch.shape)
print('t_batch.shape :', t_batch.shape)
```


```
x_train.shape : (60000, 784)
t_train.shape : (60000,)
batch_mask : [ 5651 48206  7316 23124 43701 28837 46731 46632 27684  3970]
x_batch.shape : (10, 784)
t_batch.shape : (10,)
```

60,000개의 Train data와 784개의 열(28 x 28)인 데이터를 추출했습니다. t_train에는 60,000개의 데이터 정답이 저장되어 있습니다. 여기서 batch_size를 10으로 설정하여, 10개의 무작위 데이터를 추출했습니다.

>mini batch가 '대표성(representation)'을 가진다면, 전체의 '**근사치**'를 구할 수 있습니다. 그렇기 때문에 mini-batch를 여러 번 뽑아 반복하는 **SGD(Stochastic Gradient Descent) 방식**의 학습이 가능하게 합니다. SGD에 대해서는 이후 자세하게 다루겠습니다.


### 2.4 (배치용) Cross Entropy(CE)
mini-batch를 이용하기 때문에 loss function도 이에 맞게 수정할 필요가 있습니다. 정답 label의 표기 방식에 따라 각각 구현해 보겠습니다.


```
# One-hot
def cross_entropy_error(y, t):
   if y.ndim == 1:
       t = t.reshape(1, t.size)
       y = y.reshape(1, y.size)

   batch_size = y.shape[0]
   return -np.sum(t * np.log(y)) / batch_size
```


```
# label
def cross_entropy_error(y, t):
   if y.ndim == 1:
       t = t.reshape(1, t.size)
       y = y.reshape(1, y.size)

   batch_size = y.shape[0]
   return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size # y[0, t_1], y[1, t_2], ...

```
<br><br>

아래 코드의 return부분을 설명하겠습니다. 먼저 np.log의 공식문서 내용입니다.
![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/48356954/e064cf43-09b7-48c5-b20b-17eef7a81322)
numpy log
,로 구분된 각각의 값을 array 형태로 return 합니다. 즉, np.arange를 통해 batch_size만큼의 array([0,1,2,...batch_size])를 만들고 이를 실제 정답 label과 결합을 합니다. 그 이후에 log를 적용하여 CE 형태의 loss를 도출하게 됩니다.

<br><br>

### 2.5 Accuracy vs Loss function
지금까지 Loss function을 통해 신경망을 학습하는 방법을 설명했습니다. 여기서 한 가지 의문점이 발생합니다. 왜 정확도(Accuracy)가 아닌 loss function을 사용해서 매개변수의 값을 찾는 즉, 학습을 하는 것일까요?



바로 **'미분'의 역할**에 주목할 필요가 있습니다. 신경망 학습에서 loss를 가능한 작게 하는 매개변수를 찾습니다. 이때 매개변수의 미분(기울기)을 계산하고, 이를 토대로 값을 갱신합니다. 그렇기 때문에 미분값이 0에 가까워지게끔 학습이 되고, 이는 loss를 줄이는 방식이 됩니다.



반면, 정확도를 지표로 사용하게 되면 매개변수의 미분이 대부분의 장소에서 0이 됩니다. 가령, 32% 정확도를 가지는 신경망이 있을때, 매개변수를 약간 조정하게 되면 어떻게 될까요? 32.0135%와 같은 **연속적인 값이 아닌**, 33%, 34%와 같은 **이산적인 값**으로 나타나게 됩니다. 



즉, 정확도는 매개변수의 미소한 변화에는 거의 반응을 보이지 않고, 반응이 있더라도 그 값이 불연속적으로 갑자기 변화합니다. 앞서 소개된 계단함수와 sigmoid를 생각해 보면 됩니다.

![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/48356954/32c71e3e-62c7-49b3-89c1-d013c989b5c1)
<br><br>

## 3. 미분
loss function을 사용하는 이유의 핵심이 바로 미분이었습니다. 그렇다면 미분에 대해서 하나씩 다뤄보겠습니다.



### 3.1 수치 미분
미분은 **특정 순간의 변화량**을 뜻합니다. 가령, 1시간이라는 시간을 가능한 줄여 '한 순간'의 변화량을 얻는 것입니다.

수식으로 보면 다음과 같습니다.
![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/48356954/9672ebc6-fa09-41b4-afa9-b38ab41a825e)

**x의 작은 변화가 f(x\)를 얼마나 변화**시키느냐를 의미합니다. h는 한없이 0에 가까이 보내는 의미입니다. 이를 코드로 구현해 보겠습니다.




```
def diff(f, x):
    h = 10e-50  # 너무 작은 값은 계산이 안됨 -> 1e-4가 적당하다고 알려짐
    return (f(x + h) - f(x)) / h
```

단, 여기서 몇 가지 문제점이 있습니다. 첫 번째는 h를 정의할 때, 소수점 8자리 이하는 반올림해버리기 때문에 0으로 되어 오차가 발생합니다. 이를 해결하기 위해 10^{-4}을 이용합니다. 해당 값을 사용하면, 좋은 결과를 얻는다고 알려져 있습니다.



두 번째는 실제 값과 근삿값의 차이입니다. 바로 **f(x)의 차분**이 발생합니다. 차분이란, 임의의 두 점에서의 함숫값들의 차이를 의미합니다. 실제 구하는 값은 x 위치의 기울기지만, 우리가 구하는 값은 (x+h)와 x 사이의 기울기입니다. 아래의 그림을 보겠습니다.

![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/48356954/99ecfd1e-4cd1-4b69-a5bb-ab1ddcd97b66)
초록선이 x, x+h이고 빨간 선이 x-h, x+h, 파란색이 x일 때의 기울기입니다. 실제로 x를 중심으로 그 전후의 차분을 계산하는 것이 실제 접선과 더 근사한 값을 구할 수 있습니다. 이러한 차분을 **중심 차분 혹은 중앙 차분**이라 합니다. 이를 개선한 코드는 다음과 같습니다.


```
def numerical_diff(f, x):
   h = 1e-4  # 0.0001
   return (f(x+h) - f(x-h)) / (2*h) # 오차를 줄이기 위한 차분
```

>아주 작은 차분을 이용하여 미분하는 것이 **수치 미분**입니다. 우리가 일반적으로 수식을 전개하여 미분하는 것은 **해석적 미분**이라 표현합니다.


### 3.2 편미분
변수가 x하나가 아닌 2개 이상의 변수라면 어떻게 미분을 할까요? 이럴 때 적용되는 미분이 바로 **편미분**입니다. 조금 더 고급스럽게 표현하면 **다변수함수의 미분**입니다. 간단한 예제로 편미분을 직접 코드로 구현해 보겠습니다.


```
def function_tmp1(x0):
  return x0*x0 + 4.0**2.0
  
def function_tmp2(x1):
  return 3.0**2.0 + x1*x1
  
print(f"x0 : {numerical_diff(function_tmp1, 3.0)}")
print(f"x1 : {numerical_diff(function_tmp2, 4.0)}")
```


```
x0 : 6.00000000000378
x1 : 7.999999999999119
```

실제 값인 해석적 미분값인 6, 8과 거의 유사하게 나옴을 알 수 있습니다.

## 4. Gradient
앞서 구했던 편미분은 변수별로 따로 계산을 했습니다. 하지만 편미분은 변수 모두에 대하여 동시에 계산할 수 있습니다.

이처럼 모든 변수의 편미분을 벡터로 정리한 것을 **gradient(기울기)** 라고 합니다. 앞서 구한 편미분을 일반화하는 코드를 작성해 보겠습니다.


```
def func_2(x):
    return x[0] ** 2 + x[1] ** 2    # np,sum(x ** 2) 동일

def gradient(f, x):
    h = 1e-4
    grad = np.zeros_like(x) # x와 shape이 같은 배열 생성

    for idx in range(x.size):
        tmp_val = x[idx]

        # f(x+h)
        x[idx] = tmp_val + h
        fxh1 = f(x)

        # f(x-h)
        x[idx] = tmp_val - h
        fxh2 = f(x)

        grad[idx] = (fxh1 - fxh2) / (2*h)
        x[idx] = tmp_val

    return grad

print(gradient(func_2, np.array([3.0, 4.0])))
print(gradient(func_2, np.array([0.0, 2.0])))
print(gradient(func_2, np.array([3.0, 0.0])))
```

gradient 함수는 인자로 함수와 변수를 받습니다. x는 numpy array이므로 각각에 대한 수치 미분을 구하게 됩니다. 그렇기 때문에 x값 전체에 대한 편미분을 한 번에 구할 수 있습니다. 

<br>

기울기를 그림으로 나타내면 다음과 같습니다.

![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/48356954/caa2031f-71b4-45fd-87b6-31c9311077a1)

<br>
기울기는 각 시점에서 낮아지는 방향을 가리킵니다. 더 정확히 말하자면 **기울기가 가리키는 방향은 각 위치에서 함수의 출력 값을 가장 크게 줄이는 방향**입니다.



### 4.1 경사하강법(Gradient descent)
앞서 최적의 매개변수를 찾기 위해 loss가 최소가 되게 했었습니다. 다만, 일반적인 문제의 loss function은 매우 복잡합니다. 매개변수의 공간이 광대하여 최소가 되는 지점을 짐작하기가 어렵습니다. 그렇기 때문에 기울기는 이용하여 최솟값을 찾는 방식이 **경사하강법(gradient descent)** 입니다.

<br>

주의해야 할 점은 **각 지점에서 함수의 값을 낮추는 방안을 제시하는 것이 기울기**입니다. 기울기가 가리키는 곳이 무조건 최솟값이 되고, 그 방향이 정답인지는 알 수 없습니다. 실제로 다변수 함수를 시각화해보면, 해당 방향에서의 기울기가 최솟값이 되지 않는 경우가 많습니다.

![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/48356954/2f855118-122a-4fc7-b969-82a7459a24e4)
<br>
위 그림에서 보다시피, 기울기가 줄어든다고 반드시 최솟값이 되는 것은 아닙니다. 이를 **극소점(local minimum)** 이라 부릅니다. 또 해당 함수에서의 최솟값을 **global minimum**이라고 부릅니다. 아래 그림을 보면 이해가 되실 겁니다.

![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/48356954/42ed1027-bf4c-495d-a6cb-46cab9977c6b)
<br>
이처럼 기울기를 이용하여 해당 방향으로 나아가는 학습 방법을 경사법(gradient method)라 합니다. 이를 학습에 이용할 때 고려해야 할 사항이 있습니다. 바로 **학습률(learning rate)** 입니다. 한 번의 학습으로 매개변수 값을 얼마나 경신하느냐를 정하는 것입니다. 수식으로 살펴보겠습니다.

![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/48356954/e8971d51-e04f-4110-ade5-326fc8772bbd)

해당 수식은 \(x_0\), \(x_1\)에서 매개변수 값을 얼마나 갱신시키는지 나타내는 수식입니다. 여기서 \(eta\)가 학습률로, 값이 너무 크거나 작으면 올바른 방향으로 나아가기 어렵습니다. 일반적으로 0.01, 0.001과 같은 값을 사용합니다. 이를 코드로 구현해 보겠습니다.


```
def gradient_descent(f, init_x, lr=0.01, step_num = 100):
    x = init_x

    for i in range(step_num):
        grad = gradient(f, x)
        x -= lr * grad

    return x
    
# lr이 적합할 경우
init_x = np.array([-3.0, 4.0])
print(gradient_descent(func_2, init_x=init_x, lr = 0.1, step_num=100))

# lr이 작을경우
init_x = np.array([-3.0, 4.0])
print(gradient_descent(func_2, init_x=init_x, lr = 1e-10, step_num=100))

# lr이 클 경우
init_x = np.array([-3.0, 4.0])
print(gradient_descent(func_2, init_x=init_x, lr = 10.0, step_num=100))
```

```
array([-6.11110793e-10,  8.14814391e-10])
array([-2.99999994,  3.99999992])
array([-2.58983747e+13, -1.29524862e+12]
```


이처럼 학습률을 어떻게 설정하냐에 따라 값이 굉장히 다양하게 나옵니다. 해당 예시에서는 0.1에서 0에 가까운 결과가 나왔습니다. 그렇기 때문에 해당 학습률이 적합하다고 볼 수 있습니다.



### 4.2 신경망 기울기
이제 본격적으로 신경망에서 기울기를 구해보겠습니다. 신경망은 행렬 형태로 가중치가 되어 있기 때문에 각각의 원소별로 편미분을 진행해야 합니다. 아래 수식을 보면서 이해해 보겠습니다.

![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/48356954/0c95e22e-2e93-4fd6-81c0-1e30700e8206)

 이제 본격적으로 신경망으로 기울기를 구하는 코드를 구현해 보겠습니다. 해당 신경망의 이름을 simpleNet으로 정의하겠습니다.


```
import sys, os
sys.path.append('common dir path')
import numpy as np
from functions import softmax, cross_entropy_error
from gradient import numerical_gradient

class simpleNet:
    def __init__(self):
        self.W = np.random.randn(2, 3)  # 정규 분포에서 난수 생성

    def predict(self, x):
        return np.dot(x, self.W)

    def loss(self, x, t):
        z = self.predict(x)
        y = softmax(z)
        loss = cross_entropy_error(y, t)

        return loss
        
net = simpleNet()
print("Network Weight")
print(net.W)

x = np.array([0.6, 0.9])
p = net.predict(x)
print("\nPredict")
print(p)    # x dot W -> (1 x 2) (2 x 3) -> (1 x 3)

t = np.array([0, 0, 1])
l = net.loss(x, t)
print("\nLoss")
print(l)
```

```
Network Weight
[[ 2.33985046  0.21460797  1.36117277]
 [ 0.09003226 -0.88783281  0.37000278]]

Predict
[ 1.48493931 -0.67028475  1.14970616]

Loss
0.9401216724176118
```

각각의 입력값에 대한 예측값, gradient값을 다음과 같이 구할 수 있음을 알 수 있습니다. 해당 신경망은 1층인 단층 신경망 입니다. 이제 2층 신경망으로 학습 과정 전체를 구현해 보겠습니다.



## 5. 신경망 학습
신경망 학습의 절차를 살펴보겠습니다.


**전체**
<br>

신경망에서 가중치와 편향의 최적의 값을 찾도록 Train data에서 조정하는 과정을 학습이라 합니다. 아래 4단계를 수행합니다.

<br>

**1단계 - mini-batch**

Train data 일부를 무작위 sampling을 진행합니다. 이를 mini-batch라 하고, mini-batch의 loss 값을 줄이는 것이 목표
<br>

**2단계 - gradient**

mini-batch loss를 줄이기 위해 각 가중치 매개변수의 편미분을 통한 gradient를 구합니다. gradient는 loss값을 작게 하는 방향을 제시
<br>

**3단계 - 매개변수 갱신**

가중치 매개변수를 gradient 방향으로 갱신
<br>

**4단계 - 반복**

1 ~ 3단계 반복

<br>
여기서 매개변수를 mini-batch로 무작위 복원 추출을 진행하기 때문에, SGD(확률적 경사하강법)이라고 부릅니다. MNIST를 이용하여 2층 신경망, mini-batch를 이용한 SGD 방식의 신경망을 코드로 구현하겠습니다.
<br>
<br>

```
import sys, os
import numpy as np
sys.path.append('common dir path')
from functions import *
from gradient import numerical_gradient

class TwoLayerNet:

    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):

        # weight reset
        self.params = {}
        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)
        self.params['b1'] = np.zeros(hidden_size)

        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)
        self.params['b2'] = np.zeros(output_size)

    def predict(self, x):
        W1, W2 = self.params['W1'], self.params['W2']
        b1, b2 = self.params['b1'], self.params['b2']

        a1 = np.dot(x, W1) + b1
        z = sigmoid(a1)
        a2 = np.dot(z, W2) + b2
        y = softmax(a2)

        return y

    def loss(self, x, t):
        y = self.predict(x)

        return cross_entropy_error(y, t)

    def accuracy(self, x, t):
        y = self.predict(x)
        y = np.argmax(y, axis=1)
        t = np.argmax(t, axis=1)

        acc = np.sum(y == t) / float(x.shape[0])
        return acc

    def numerical_gradient(self, x, t):
        loss_W = lambda W: self.loss(x, t)

        grads = {}
        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])
        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])
        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])
        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])

        return grads
        
net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)

print(f"W1 shape : {net.params['W1'].shape}")
print(f"b1 shape : {net.params['b1'].shape}")
print(f"W2 shape : {net.params['W2'].shape}")
print(f"b2 shape : {net.params['b2'].shape}")

x = np.random.rand(1, 784)  # 더미 입력 데이터(1장 분량)
t = np.random.rand(1, 10)  # 더미 정답 레이블(1장 분량)
y = net.predict(x)

grads = net.numerical_gradient(x, t)  # 기울기 계산

print(f"W1 grad shape : {net.params['W1'].shape}")
print(f"b1 grad shape : {net.params['b1'].shape}")
print(f"W2 grad shape : {net.params['W2'].shape}")
print(f"b2 grad shape : {net.params['b2'].shape}")
```


```
W1 shape : (784, 100)
b1 shape : (100,)
W2 shape : (100, 10)
b2 shape : (10,)

W1 grad shape : (784, 100)
b1 grad shape : (100,)
W2 grad shape : (100, 10)
b2 grad shape : (10,)
```

<br>


mini-batch를 사용할 때는 전체 데이터에서 임의의 데이터를 복원 추출하여 mini-batch를 만듭니다. 이후, iteration(반복) 횟수를 설정하여 계속해서 학습을 반복합니다. 그렇게 되었을 때, 실제 전체 데이터를 학습한 결과와 거의 유사한 loss값을 얻을 수 있습니다. 코드로 살펴보겠습니다. 여기서는 iteration을 10,000번 반복하겠습니다.


```
import sys, os
sys.path.append(os.pardir)
import numpy as np
import matplotlib.pyplot as plt
from dataset.mnist import load_mnist
from two_layer_net import TwoLayerNet

# 데이터 읽기
(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)

network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)

# 하이퍼파라미터
iters_num = 10000  # 반복 횟수를 적절히 설정
train_size = x_train.shape[0]
batch_size = 100   # 미니배치 크기
learning_rate = 0.1

train_loss_list = []

for i in range(iters_num):
    # 미니배치 획득
    batch_mask = np.random.choice(train_size, batch_size)
    x_batch = x_train[batch_mask]
    t_batch = t_train[batch_mask]

    # 기울기 계산
    #grad = network.numerical_gradient(x_batch, t_batch)
    grad = network.gradient(x_batch, t_batch)

    # 매개변수 갱신
    for key in ('W1', 'b1', 'W2', 'b2'):
        network.params[key] -= learning_rate * grad[key]

    # 학습 경과 기록
    loss = network.loss(x_batch, t_batch)
    train_loss_list.append(loss)
```

<br>

해당 loss의 변화를 그래프로 살펴보겠습니다.

![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/48356954/e02c3c0d-2d51-4960-908c-fea94c2c1b72)
그래프를 보면, SGD 방식으로도 충분히 낮은 loss로 수렴함을 알 수 있습니다. 이제 최종적으로 test data로 정확도를 평가해 보겠습니다.



### 5.1 Test data 평가
앞서 iteration을 통해, loss가 낮아짐을 확인했습니다. 즉, 학습이 잘 진행됨을 알 수 있습니다. 그러나 Train data에서 mini-batch를 이용했기 때문에, 일반화 성능을 장담할 수 없습니다. 즉, 과적합(Overfitting)을 확인해야 합니다. 여기서는 epoch당 train, test data에 대한 정확도를 평가합니다.

>epoch은 단위입니다. 1 epoch은 학습에서 전체 데이터에 대해 한 번 학습을 완료한 상태를 의미합니다.


```
import sys, os
sys.path.append(os.pardir)
import numpy as np
import matplotlib.pyplot as plt
from dataset.mnist import load_mnist
from two_layer_net import TwoLayerNet

# 데이터 읽기
(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)

network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)

# 하이퍼파라미터
iters_num = 10000
train_size = x_train.shape[0]
batch_size = 100   # 미니배치 크기
learning_rate = 0.1

train_loss_list = []
train_acc_list = []
test_acc_list = []

# 1에폭당 반복 수
iter_per_epoch = max(train_size / batch_size, 1)

for i in range(iters_num):
    # 미니배치
    batch_mask = np.random.choice(train_size, batch_size)
    x_batch = x_train[batch_mask]
    t_batch = t_train[batch_mask]

    # 기울기 계산
    #grad = network.numerical_gradient(x_batch, t_batch)
    grad = network.gradient(x_batch, t_batch)

    # 매개변수 갱신
    for key in ('W1', 'b1', 'W2', 'b2'):
        network.params[key] -= learning_rate * grad[key]

    # 학습 경과 기록
    loss = network.loss(x_batch, t_batch)
    train_loss_list.append(loss)

    # 1에폭당 정확도 계산
    if i % iter_per_epoch == 0:
        train_acc = network.accuracy(x_train, t_train)
        test_acc = network.accuracy(x_test, t_test)
        train_acc_list.append(train_acc)
        test_acc_list.append(test_acc)
        print("train acc, test acc | " + str(train_acc) + ", " + str(test_acc))
```
<br>
앞의 결과를 그래프로 그려보면 다음과 같다.

![image](https://github.com/kw-chi-community/CHIC_24_machine-learning-study/assets/48356954/4ddf65af-ab18-403e-9e54-aa61359edfe4)
Train, test data모두 epoch을 반복할수록 정확도가 개선되고 있습니다. 또 train, test의 정확도가 거의 유사하기 때문에 과적합(overfitting)이 이루어지지 않음을 알 수 있습니다.



## 6. 정리
이제까지 배운 학습에 신경망을 학습하는 방식을 전체적으로 구현하는 시간이었습니다. 학습을 하기 위해 loss function이라는 지표를 도입하고, 이를 작게 하는 매개변수를 찾기 위해 gradient 개념도 소개되었습니다. 또 mini-batch를 이용하여 SGD 방식의 학습법도 관찰할 수 있었습니다. 다만, 수치 미분을 이용한 신경망 학습의 단점은 구현은 단순하나, 시간이 오래 걸리는 단점이 존재합니다.
