### I. Scaler

실습용으로 준비된 데이터는 잘 가공되어 있지만, 실전 데이터는 누락된 값 또는 불균일한 형태일 수 있으므로 \
그대로 사용 시 제대로 된 결과를 얻기 난해함. -> 데이터 전처리의 필요성

AI 모델 구현 시, 데이터 전처리 과정에서 필요한 것 중 하나는 "스케일 조정", \
이를 하는 것이 바로 "scaler"
-특성의 단위나 범위가 다른 매우 많은 데이터를 설정한 기준 내에서 평가 가능
\
scikitlearn에서 제공하는 스케일러

#### 1. StandardScaler
- 평균 0, 분산 1로 조정

Q. standard는 만능인가? \
A.  NO. outlier에 취약함. 
- scaler의 의의는 데이터의 수치화 
- 데이터 분포의 시각화가 필요한데, 데이터가 표준 정규분포를 따를 때 전제하에는 효율적이나, \
특정 이상값 존재 시 사용하기 난해하다. 
혹은 개형이 치우친 경우 \
(왜도의 절댓값이 큰 경우, 여기서 왜도는 분포의 비대칭도를 의미하며, 정규분포처럼 대칭인 분포는 0의 값) \
\
아래는 자주 쓰이는 다른 스케일러들

#### 2. MinMaxScaler
- 각 특성을 주어진 범위 내의 값으로 변환
- ex) [0,1] : 최댓값을 1, 최솟값을 0으로 범위 조정

#### 3. RobustScaler
- 평균과 분산을 사용한 StandardScaler과 달리 중앙값과 사분위값(IQR)을 사용
- 이상치의 영향 최소화

그 외 : log, sqrt

특정 스케일러가 만능이다! (X)
데이터의 특성에 따라 적합한 방식으로 선택하고, 왜 쓸 건지 이유를 필히 알도록.


#### +추가 
from sklearn.preprocessing import (Scaler 클래스) \
Scaler 객체를 통해 데이터의 스케일링 변환에 이용되는 대표적인 메소드는 \
fit(), transform(), fit_transform()이 있다.
fit()
- 해당 스케일러의 데이터 변환 정보를 학습(train에만 적용)\
transform()
- 데이터 변환 실제 수행(train, test 모두 적용)
fit_transform()은 쉽게 말해 fit + transform(모두 적용)

만약 fit_transform을 test data에도 적용하게 되면 test data로부터 새로운 평균값과 분산값을 얻게 된다.\
즉 모델이 test data도 학습하게 됨(Data Leakage)\
모델은 train data에 있는 평균과 분산을 학습하게 되는데, 이렇게 학습된 scaler()의 파라미터는 test data를 scale하는데 사용됨\
-> train data로 학습된 scaler()의 파라미터를 통해 test data의 feature값들이 scale 됨

train에 적용된 스케일링 정보를 그대로 test에 적용해야 한다. \
scaled_X_test = scaler.transform(X_test) 은 가능하나, 객체의 메소드로 fit, fit_transform을 사용해서는 안 된다는 것이다. test data가 유출되는 꼴이다.




### II. 결정계수(R-Squre, R^2)

#### R square
- '독립변수가 종속변수를 얼만큼 설명해 주는가?' 에 대한 지표
- 계산된 예측값이 실제 y값을 얼마나 설명하는지를 나타냄, 모형의 설명력 
-  R square = 1- SSE/SSR 
- 설명 지표이나 값 자체는 특정 기준이 없다.
- 보통 0과 1 사이의 범위이나 코드 구현 시 특정한 경우에 음수가 나올 수도 있다.
(제대로 설명하지 못하며, 해당 모델이 기준 모델보다 예측을 못 함) 
- 1의 값을 가진다는 것은 주어진 데이터를 잘 설명한다는 것이나, 과적합 가능성 有
즉, 새로운 데이터에 대한 일반화가 난해할 수 있음

#### adjusted R square
- 독립변수의 유의 여부와 별개로 그 수가 늘어나면 결정계수가 높아지는 
기존 R squre의 단점을 보완, 즉 독립변수의 개수를 고려
