- 훈련 세트 : 모델 훈련
- 테스트 세트 : 모델 평가

k - 최근접 알고리즘은 입력에 따른 결과(=타깃)가 주어졌을 때만 판단 가능 => 지도학습
여기서 입력과 결과 = 훈련 데이터
입력에는 특성이 들어감
=>지도 학습은 정답을 알고, 알고리즘이 정답 맞히는 것 학습
=> 알고리즘 성능 제대로 평가하려면 훈련 데이터와 평가에 사용할 데이터가 달라야함 = 테스트 세트와 훈련 세트가 각각 필요한 이유임

비지도학습은 정답 사용 안함 => 맞히기 불가능 but 데이터 잘 파악하거나 변형하는데 도움 줌

```
fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0,
                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0,
                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8,
                10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]
fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0,
                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0,
                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7,
                7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]

fish_data = [[l,w] for l, w in zip(fish_length,fish_weight)]
fish_target = [1]*35 + [0]*14
#전체 데이터는 49개(도미 35개, 빙어 14개)

from sklearn.neighbors import KNeighborsClassifier
kn = KNeighborsClassifier()

#배열에 접근하는 방법들
print(fish_data[4])
print(fish_data[2:5])
print(fish_data[44:])

#위와 같은 방법 이용해서 처음 35개 트레이닝 세트에 넣고 나머지 14개 테스트 세트에 넣음
train_input = fish_data[:35]
train_target = fish_target[:35]
test_input = fish_data[35:]
test_target = fish_target[35:]

#각 세트별로 input과 target(=output) 설정

kn = kn.fit(train_input, train_target)
kn.score(test_input, test_target)

#결과값 : 0.0 => 성능 최악, 이유는 밑에 설명
```
**샘플링 편향**  
: *샘플이 골고루 섞여있지 않고 샘플링이 한쪽으로 치우침*  
위 예시에서는 앞 35개 데이터가 다 도미라서 트레이닝 세트에는 빙어가 하나도 들어있지 않게 되어 빙어를 올바르게 분류하지 못하게 됨 => 빙어와 도미를 골고루 섞이게 만들어야 함  
.   
이를 간단하게 처리할 수 있게 나온게 파이썬의 라이브러리인 **넘파이** 임

**넘파이**   
: 파이썬의 대표적인 배열 라이브러리, 고차원 배열을 손쉽게 만들고 조작할 수 있는 간편한 도구 제공  
파이썬 리스트를 넘파이 배열로 바꾸는 법 : 넘파이 array() 함수에 파이썬 리스트 전달하면 끝

```
import numpy as np

input_arr = np.array(fish_data)
target_arr = np.array(fish_target)

print(input_arr)
#넘파이는 배열의 차원을 구분하기 쉽도록 행과 열을 가지런히 출력함

print(input_arr.shape)
#shape속성은 배열의 크기를 알려줌(이것도 넘파이에서 제공)
#(샘플 수, 특성 수)를 출력 => (행, 열)

#target과 sample이 함께 움직여야 함 => 인덱스를 섞은 다음 input_arr와 target_arr에서 샘플 선택

np.random.seed(42) #numpy에서 무작위 결과 만드는 함수는 실행할 때마다 다른 결과 출력함 그래서 일정한 결과 얻기 위해 그냥 랜덤 시드 42로 설정한 것임 실제 데이터 셋 할 때는 안해도 됨
index = np.arange(49) #arange에 이렇게 정수 전달만 해도 해당 크기의 배열 만듦
np.random.shuffle(index) #랜덤으로 돌리기

print(index)

#배열 인덱싱 사용해서 훈련세트, 테스트 세트로 나누기

#훈련 세트
train_input = input_arr[index[:35]]
train_target = target_arr[index[:35]]
#테스트 세트
test_input = input_arr[index[35:]]
test_target = target_arr[index[35:]]

#도미와 빙어가 잘 섞였는지 확인 위한 그래프 코드
import matplotlib.pyplot as plt
plt.scatter(train_input[:,0], train_input[:,1])
plt.scatter(test_input[:,0], test_input[:,1])
plt.xlabel('length')
plt.ylabel('weight')
plt.show()

#모델 훈련
#KNeighborsClassifier 클래스 객체는 이전에 학습한 모든 것 잃어버림 => 이전 모델 그대로 두고 싶으면 객체 새로 만들어야함
#여기서는 그냥 위에서 만들어놓은 kn객체 그대로 사용
kn = kn.fit(train_input, train_target) #훈련시키고
kn.score(test_input, test_target) #test에 있는 거 넣기
#결과값 : 1.0 => 테스트 세트에 있는 모든 생선 맞춤

#예측과 실제 값이 동일
kn.predict(test_input)

```

정리  
훈련 데이터를 훈련 세트와 테스트 세트로 나누고 훈련 세트에서는 모델 훈련, 테스트 세트에서는 모델 평가  
넘파이 이용하고 shuffle()함수 사용해서 배열의 인덱스 섞음
